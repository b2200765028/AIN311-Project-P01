{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f8d8aa5",
      "metadata": {
        "id": "6f8d8aa5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from datasets import list_datasets, load_dataset\n",
        "from pprint import pprint\n",
        "import random\n",
        "import keras\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64e89eaa",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "92f65ba82821433b818beee290044686"
          ]
        },
        "id": "64e89eaa",
        "outputId": "dec49919-2d2a-48b5-b945-661fb527b31f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset squad (C:/Users/user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92f65ba82821433b818beee290044686",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = load_dataset('squad') ## downloading squad dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d26853",
      "metadata": {
        "id": "e7d26853",
        "outputId": "12ce5148-3716-4ea9-fbf3-74921ed749c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 87599\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 10570\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a653459",
      "metadata": {
        "id": "6a653459"
      },
      "outputs": [],
      "source": [
        "train_squad = pd.DataFrame(dataset[\"train\"])\n",
        "test_squad = pd.DataFrame(dataset[\"validation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8e6846",
      "metadata": {
        "id": "9d8e6846",
        "outputId": "e27ca883-2cdb-4f78-822c-cbd44980e46e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 87599 entries, 0 to 87598\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        87599 non-null  object\n",
            " 1   title     87599 non-null  object\n",
            " 2   context   87599 non-null  object\n",
            " 3   question  87599 non-null  object\n",
            " 4   answers   87599 non-null  object\n",
            "dtypes: object(5)\n",
            "memory usage: 3.3+ MB\n"
          ]
        }
      ],
      "source": [
        "train_squad.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aca8efa9",
      "metadata": {
        "id": "aca8efa9",
        "outputId": "a43a9ece-8ac7-420a-dcc6-d366df865bbb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5733be284776f41900661182</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
              "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5733be284776f4190066117f</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5733be284776f41900661180</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
              "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5733be284776f41900661181</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5733be284776f4190066117e</td>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What sits on top of the Main Building at Notre...</td>\n",
              "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id                     title  \\\n",
              "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
              "1  5733be284776f4190066117f  University_of_Notre_Dame   \n",
              "2  5733be284776f41900661180  University_of_Notre_Dame   \n",
              "3  5733be284776f41900661181  University_of_Notre_Dame   \n",
              "4  5733be284776f4190066117e  University_of_Notre_Dame   \n",
              "\n",
              "                                             context  \\\n",
              "0  Architecturally, the school has a Catholic cha...   \n",
              "1  Architecturally, the school has a Catholic cha...   \n",
              "2  Architecturally, the school has a Catholic cha...   \n",
              "3  Architecturally, the school has a Catholic cha...   \n",
              "4  Architecturally, the school has a Catholic cha...   \n",
              "\n",
              "                                            question  \\\n",
              "0  To whom did the Virgin Mary allegedly appear i...   \n",
              "1  What is in front of the Notre Dame Main Building?   \n",
              "2  The Basilica of the Sacred heart at Notre Dame...   \n",
              "3                  What is the Grotto at Notre Dame?   \n",
              "4  What sits on top of the Main Building at Notre...   \n",
              "\n",
              "                                             answers  \n",
              "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
              "1  {'text': ['a copper statue of Christ'], 'answe...  \n",
              "2  {'text': ['the Main Building'], 'answer_start'...  \n",
              "3  {'text': ['a Marian place of prayer and reflec...  \n",
              "4  {'text': ['a golden statue of the Virgin Mary'...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_squad.head()\n",
        "## we dont need id gonna drop it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3e25c00",
      "metadata": {
        "id": "e3e25c00"
      },
      "outputs": [],
      "source": [
        "train_squad.drop(\"id\",axis=1,inplace=True)\n",
        "test_squad.drop(\"id\",axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d27da01",
      "metadata": {
        "id": "9d27da01",
        "outputId": "dd470f24-0be8-4f6c-d9b0-7d2f98193f67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "New_York_City            817\n",
              "American_Idol            802\n",
              "Beyoncé                  758\n",
              "Frédéric_Chopin          697\n",
              "Queen_Victoria           680\n",
              "                        ... \n",
              "Great_Plains              47\n",
              "Tristan_da_Cunha          44\n",
              "Pitch_(music)             36\n",
              "Matter                    24\n",
              "Myocardial_infarction     22\n",
              "Name: title, Length: 442, dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_squad[\"title\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41688f63",
      "metadata": {
        "id": "41688f63",
        "outputId": "b36a1a93-e0e9-427c-fde6-58742eb7537e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(120, 10)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "avg_words_context = round(sum([len(i.split()) for i in train_squad[\"context\"]])/len(train_squad))\n",
        "avg_words_question = round(sum([len(i.split()) for i in train_squad[\"question\"]])/len(train_squad))\n",
        "avg_words_context,avg_words_question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc56063",
      "metadata": {
        "id": "ddc56063",
        "outputId": "6c4ca1c3-0c89-4c0d-a6dc-583ed71cd962"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(653, 40)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_words_context = (max([len(i.split()) for i in train_squad[\"context\"]]))\n",
        "max_words_question = (max([len(i.split()) for i in train_squad[\"question\"]]))\n",
        "max_words_context,max_words_question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bacae779",
      "metadata": {
        "id": "bacae779",
        "outputId": "d8b70f3f-bb66-4a9c-b906-22d1ee3509a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "146.65"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(653*0.1 + 120*1.9) / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aea34046",
      "metadata": {
        "id": "aea34046"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10f5434",
      "metadata": {
        "id": "b10f5434"
      },
      "outputs": [],
      "source": [
        "encoder_text = train_squad[\"context\"][:4000]\n",
        "decoder_text = train_squad[\"question\"][:4000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce802b5d",
      "metadata": {
        "id": "ce802b5d"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def token_fit(texts):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "    dictionary = tokenizer.word_index\n",
        "    \n",
        "    word2i ={k:v for (k,v) in dictionary.items()}\n",
        "    i2word = {v:k for (k,v) in word2i.items()}\n",
        "    \n",
        "    return tokenizer, word2i,i2word\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a4370b4",
      "metadata": {
        "id": "6a4370b4"
      },
      "outputs": [],
      "source": [
        "tokenizer,word2i,i2word = token_fit(encoder_text+decoder_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea6232d",
      "metadata": {
        "id": "9ea6232d",
        "outputId": "18548165-314d-4547-86ee-a32498b521b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most occured 10 words in vocab\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['the', 'of', 'in', 'and', 'to', 'a', 'was', 'for', 'on', 'as']"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Most occured 10 words in vocab\")\n",
        "sorted(tokenizer.word_counts,key=tokenizer.word_counts.get,reverse=True)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "893bd550",
      "metadata": {
        "id": "893bd550",
        "outputId": "b9ae7e20-31f3-432a-97e3-5cd9e341f075"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12113"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size= len(word2i)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb489b5",
      "metadata": {
        "id": "bbb489b5"
      },
      "outputs": [],
      "source": [
        "def text2sequence(context,question,tokenizer):\n",
        "    encoder_seq = tokenizer.texts_to_sequences(context)\n",
        "    decoder_seq = tokenizer.texts_to_sequences(question)\n",
        "    \n",
        "    return encoder_seq,decoder_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2ccd68",
      "metadata": {
        "id": "8c2ccd68"
      },
      "outputs": [],
      "source": [
        "encoder_seq,decoder_seq = text2sequence(encoder_text,decoder_text,tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "299b0858",
      "metadata": {
        "id": "299b0858",
        "outputId": "f4f0bf91-1ada-46c4-a4a7-6846443e3c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text \n",
            "-----------\n",
            " Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
            "Turned into sequences \n",
            "-----------\n",
            " [8672, 1, 97, 35, 6, 556, 658, 779, 1, 274, 8673, 1148, 2376, 16, 6, 1170, 2451, 2, 1, 3917, 1400, 1926, 3, 3329, 2, 1, 274, 258, 4, 3454, 23, 16, 6, 5041, 2451, 2, 5778, 12, 5779, 8674, 12, 1, 702, 8675, 8676, 739, 8677, 599, 5, 1, 274, 258, 16, 1, 2531, 2, 1, 4684, 2076, 1926, 907, 1, 2531, 16, 1, 2618, 6, 8678, 351, 2, 4117, 4, 8679, 23, 16, 6, 5780, 2, 1, 2618, 14, 3739, 606, 70, 1, 3917, 1400, 8680, 480, 5, 2532, 8681, 8682, 3, 7988, 14, 1, 327, 2, 1, 274, 1548, 4, 3, 6, 1081, 233, 11, 6389, 206, 158, 4118, 4, 1, 1148, 2376, 16, 6, 2182, 499, 2131, 2451, 2, 1400]\n"
          ]
        }
      ],
      "source": [
        "print(\"Original Text \\n-----------\\n\",encoder_text[0])\n",
        "print(\"Turned into sequences \\n-----------\\n\",encoder_seq[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeb4df62",
      "metadata": {
        "id": "eeb4df62"
      },
      "outputs": [],
      "source": [
        "\n",
        "max_len_enc = 0\n",
        "max_len_dec = 0\n",
        "\n",
        "for enc,dec in zip(encoder_seq,decoder_seq):\n",
        "    if len(enc) > max_len_enc:\n",
        "        max_len_enc = len(enc)\n",
        "    if len(dec) > max_len_dec:\n",
        "        max_len_dec= len(dec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ef37fa3",
      "metadata": {
        "id": "8ef37fa3",
        "outputId": "da6555b8-2119-4b25-929a-a17ef1c42571"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(518, 29)"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_len_enc,max_len_dec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a96a55",
      "metadata": {
        "id": "70a96a55"
      },
      "outputs": [],
      "source": [
        "from keras.utils import pad_sequences\n",
        "encoder_data = pad_sequences(encoder_seq,maxlen=max_len_enc,dtype=\"int32\",padding=\"post\",truncating=\"post\")\n",
        "decoder_data = pad_sequences(decoder_seq,maxlen=max_len_dec,dtype=\"int32\",padding=\"post\",truncating=\"post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "452db2db",
      "metadata": {
        "id": "452db2db"
      },
      "source": [
        "#### as we can see it added extra zeros to make them same size(we selected post to add zeros after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59c75656",
      "metadata": {
        "id": "59c75656",
        "outputId": "1a483777-8016-46c8-8cdd-c63b705eece9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  12,    1,  702, 8675, 8676,  739, 8677,  599,    5,    1,  274,\n",
              "        258,   16,    1, 2531,    2,    1, 4684, 2076, 1926,  907,    1,\n",
              "       2531,   16,    1, 2618,    6, 8678,  351,    2, 4117,    4, 8679,\n",
              "         23,   16,    6, 5780,    2,    1, 2618,   14, 3739,  606,   70,\n",
              "          1, 3917, 1400, 8680,  480,    5, 2532, 8681, 8682,    3, 7988,\n",
              "         14,    1,  327,    2,    1,  274, 1548,    4,    3,    6, 1081,\n",
              "        233,   11, 6389,  206,  158, 4118,    4,    1, 1148, 2376,   16,\n",
              "          6, 2182,  499, 2131, 2451,    2, 1400,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0])"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder_data[0][40:200]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd45311a",
      "metadata": {
        "id": "cd45311a"
      },
      "source": [
        "### Pretrained embedding using glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d231965",
      "metadata": {
        "id": "4d231965",
        "outputId": "a4d20d82-8184-41d4-94c0-c6cac3bdf7ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "path_to_glove_file = os.path.join(\n",
        " \"./glove.6B.100d.txt\"\n",
        ")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d341dc43",
      "metadata": {
        "id": "d341dc43"
      },
      "outputs": [],
      "source": [
        "num_tokens = vocab_size + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a3cecfe",
      "metadata": {
        "id": "1a3cecfe"
      },
      "outputs": [],
      "source": [
        "for word, i in word2i.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b295d35",
      "metadata": {
        "id": "5b295d35",
        "outputId": "5868eed8-b44b-43b0-ebe0-4853dd43d8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted 11076 words (1037 misses)\n"
          ]
        }
      ],
      "source": [
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a56d2e1f",
      "metadata": {
        "id": "a56d2e1f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6989d271",
      "metadata": {
        "id": "6989d271",
        "outputId": "a5f215ae-256e-45a0-d373-7bbaf2a6e829"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_samples = len(encoder_seq)\n",
        "num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adf255a2",
      "metadata": {
        "id": "adf255a2",
        "outputId": "21a552f4-4c1f-4005-9374-2279b863c3c7"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (4000, 518)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [160]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m encoder_inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, max_len_enc))\n\u001b[0;32m      6\u001b[0m encoder \u001b[38;5;241m=\u001b[39m LSTM(latent_dim, return_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m encoder_outputs, state_h, state_c \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m encoder_states \u001b[38;5;241m=\u001b[39m [state_h, state_c]\n\u001b[0;32m     11\u001b[0m decoder_inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, max_len_dec))\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py:553\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m inputs, initial_state, constants \u001b[38;5;241m=\u001b[39m rnn_utils\u001b[38;5;241m.\u001b[39mstandardize_args(\n\u001b[0;32m    549\u001b[0m     inputs, initial_state, constants, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_constants\n\u001b[0;32m    550\u001b[0m )\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m constants \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;66;03m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;66;03m# input_spec to include them.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m additional_inputs \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py:232\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    230\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m--> 232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    234\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
            "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (4000, 518)"
          ]
        }
      ],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "\n",
        "latent_dim = 128\n",
        "encoder_inputs = Input(shape=(None, max_len_enc))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_data)\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, max_len_dec))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the \n",
        "# return states in the training model, but we will use them in inference.\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_data,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(max_len_dec, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5c1a231",
      "metadata": {
        "id": "b5c1a231"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d807e067",
      "metadata": {
        "id": "d807e067"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}